<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
            "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width">
  <title>TPDP 2023 – Theory and Practice of Differential Privacy</title>

  <link href="style.css" type="text/css" rel='stylesheet'>
  <link rel='stylesheet' media='screen and (max-width: 750px)'
  href='narrow.css'>

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<meta property="og:image" content="https://tpdp.journalprivacyconfidentiality.org/android-chrome-512x512.png">
<meta property="og:image:type" content="image/png">
<meta property="og:image:width" content="512">
<meta property="og:image:height" content="512">

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}})
</script>
</head>

<style>
  .image-with-text {
    display: flex;
    align-items: center;
  }

  .image-with-text p {
    margin-right: 10px;
  }
</style>

<body>

<div id="header">
  <h1>TPDP 2023 - Theory and Practice of Differential Privacy</h1>
  <h2>Boston - September 27-28, 2023 
<br>
  </h2>
</div>


<div class="program box"> <h2>Program (tentative)
</h2>
<p>
TPDP 2023 will be held in the Metcalf Trustee Center in the Boston University Questrom School of Business, at 1 Silber Way, 9th floor, Boston.
(all listed times are Eastern time)
</p>
<table  style="padding:15px; column-gap:1000px">

<p><b>Wednesday, September 27</b></p>

  <tr>
    <td style="width: 100px;">
      9:00-9:05
    </td>
    <td></td>
    <td>
       Opening Remarks
      <br>
    </td>
  </tr>

  <tr>
    <td>
      9:05-9:50
    </td>
    <td></td>
    <td>
      Keynote: Differentially Private Measurements in Advertising
      <br>
      <a href="https://pasin30055.github.io">Pasin Manurangsi</a> (Invited Speaker)
      <p style="font-size: smaller;">Digital advertising is a critical component of the internet and is powered by large-scale data analytics and machine learning models; privacy concerns around these are on the rise. In the past few years, numerous proposals have been put forth to address such concerns. Many of these proposals aim to achieve formal guarantees of differential privacy. In this talk, we will review the setting, discuss high-level ideas of proposed solutions and describe the main research challenges in the space, with focus on measurements.</p>
      <br>
    </td>
  </tr>
  
  <tr>
    <td>
      9:50-10:35
    </td>
    <td></td>
    <td>
      (Combined Talk) 
	<br>
<a href="https://arxiv.org/abs/2212.05015">Robustness Implies Privacy in Statistical Estimation</a>
      <br>
      Samuel B. Hopkins, Gautam Kamath, Mahbod Majid, Shyam Narayanan
      <br>
      <a href="https://arxiv.org/abs/2302.01855">From Robustness to Privacy and Back</a>
	<br>
	Hilal Asi, Jonathan Ullman, Lydia Zakynthinou
      <br>
	<br>
      <a href="https://arxiv.org/abs/2303.12921">Stability is Stable: Connections between Replicability, Privacy, and Adaptive Generalization</a>
      <br>
      Mark Bun, Marco Gaboardi, Max Hopkins, Russell Impagliazzo, Rex Lei, Toniann Pitassi, Satchit Sivakumar, Jessica Sorrell
      <br>
	<br>
	<a href="https://arxiv.org/abs/2301.02457">Better Differentially Private Approximate Histograms and Heavy Hitters using the Misra-Gries Sketch</a>
	<br>
	Christian Janos Lebeda, Jakub Tětek
    </td>
  </tr>  

<tr>
<td>
10:35-11:00
</td>
<td></td>
<td>
Break
</td>
</tr>

<tr>
<td>
11:00-12:30
</td>
<td></td>
<td>
Poster Session 1
</td>
</tr>

<tr>
<td>
12:30-2:00
</td>
<td></td>
<td>
Lunch Break
</td>
</tr>

  <tr>
    <td>
      2:00-2:30
    </td>
    <td></td>
    <td>
      <a href="https://arxiv.org/abs/2305.09579#:~:text=A%20private%20learner%20is%20trained,al.%2C%20FOCS%202008%5D.">Private Everlasting Prediction</a>
      <br>
      Moni Naor, Kobbi Nissim, Uri Stemmer, Chao Yan
      <br>
      <br>
	(Combined Talk)
	<br>
      Models Matter: Setting Accurate Privacy Expectations for Local and Central Differential Privacy
      <br>
      Mary Anne Smart, Priyanka Nanayakkara, Rachel Cummings, Gabriel Kaptchuk, Elissa M. Redmiles
	<br>
What Are the Chances? Explaining the Epsilon Parameter in Differential Privacy
<br>
Priyanka Nanayakkara, Mary Anne Smart, Rachel Cummings, Gabriel Kaptchuk, Elissa M. Redmiles
    </td>
  </tr>  

<tr>
<td>
2:30-3:45
</td>
<td></td>
<td>
Panel on Machine Learning, Memorization, and Privacy
<br>
<a href="https://www.bu.edu/law/profile/stacey-dogan/">Stacey Dogan</a>, <a href="http://vtaly.net">Vitaly Feldman</a>, <a href="https://katelee168.github.io">Katherine Lee</a>, <a href="https://cs-people.bu.edu/ads22/">Adam Smith</a>
</td>
</tr>

<tr>
<td>
3:45-4:15
</td>
<td></td>
<td>
Break
</td>
</tr>

<tr>
<td>
4:15-5:45
</td>
<td></td>
<td>
Poster Session 2
</td>
</tr>

</table>

<table  style="padding:15px; column-gap:1000px">

<p><b>Thursday, September 28</b></p>

  <tr>
    <td style="width: 100px;">
      09:00-09:45
    </td>
    <td></td>
    <td>
       Keynote: The Ever-evolving Intersection of Statistics and Privacy 
      <br>
	<a href="https://sites.psu.edu/sesa/">Aleksandra (Seša) Slavković</a> (Invited Speaker)
	<p style="font-size: smaller;">The challenge of mitigating disclosure risks associated with sensitive data and statistical analyses is a long-standing topic in statistics, yet many researchers and partitioners remain unfamiliar with potential ideas and solutions offered by statistical disclosure control (SDC) methodologies. Differential privacy (DP) has become a leading framework, providing mathematically verifiable privacy guarantees in a transparent manner to support the release of summary statistics and synthetic data. In this talk, I will discuss the shared statistical foundations of both SDC and DP, offering a personal and historical perspective. We will journey through how we arrived at the current state and consider the future of statistical data privacy. </p>
    </td>
  </tr>

  <tr>
    <td>
      9:45-10:15
    </td>
    <td></td>
    <td>
<a href="https://arxiv.org/abs/2305.08846">Privacy Auditing with One (1) Training Run</a>
      <br>
      Thomas Steinke, Milad Nasr, Matthew Jagielski 
      <br>
      <br>
      <a href="https://arxiv.org/abs/2210.13537">Private Online Prediction from Experts: Separations and Faster Rates</a>
      <br>
      Hilal Asi, Vitaly Feldman, Tomer Koren, Kunal Talwar
    </td>
  </tr>  

<tr>
<td>
10:15-10:45
</td>
<td></td>
<td>
Break
</td>
</tr>

<tr>
<td>
10:45-12:15
</td>
<td></td>
<td>
Poster Session 3
</td>
</tr>

<tr>
<td>
12:15-1:45
</td>
<td></td>
<td>
Lunch Break
</td>
</tr>

<tr>
<td>
1:45-2:30
</td>
<td></td>
<td>
Keynote: Concurrent Composition of Interactive Differential Privacy
<br>
<a href="https://wanrongz.github.io">Wanrong Zhang</a> (Invited Speaker)
<p style="font-size: smaller;">We initiate a study of the composition properties of interactive differentially private mechanisms. An interactive differentially private mechanism is a possibly stateful algorithm that allows an analyst to adaptively ask queries about a sensitive dataset. We focus on *concurrent* composition, where an adversary can arbitrarily interleave its queries to several interactive differentially private mechanisms, which may be feasible when differentially private query systems are deployed in practice. We prove that the main composition theorems for non-interactive differentially private mechanisms extend to the concurrent composition of interactive differentially private mechanisms. Our theorems cover the cases when differential privacy is measured using the hypothesis testing framework of f-DP, which captures standard ($\epsilon,\delta$)-DP as a special case, or using Renyi divergence of fixed order (Renyi DP). Our proof for the case of f-DP works by showing that every interactive f-DP mechanism can be simulated, on any pair of adjacent datasets, by an interactive post-processing of a non-interactive f-DP mechanism.   <br>
 
We then extend these results to the concurrent composition of interactive mechanisms with adaptively chosen privacy-loss parameters. We prove that every valid privacy filter and odometer for noninteractive mechanisms extend to the concurrent composition of interactive mechanisms if privacy loss is measured using $(\epsilon, \delta)$-DP, $f$-DP, or R\'enyi DP of fixed order. Our results offer strong theoretical foundations for enabling full adaptivity in composing differentially private interactive mechanisms, showing that concurrency does not affect privacy guarantees. <br>
 
This talk is based on joint work with Salil Vadhan, Tianhao Wang, Xin Lyu, Vicki Xu, Samuel Haney, Michael Shoemate, Grace Tian, and Andrew Vyrros.</p>
</td>
</tr>

  <tr>
    <td>
      2:30-3:00
    </td>
    <td></td>
    <td>
      <a href="https://arxiv.org/abs/2211.03128">Confidence-Ranked Reconstruction of Census Microdata from Published Statistics</a>
      <br>
      Travis Dick, Cynthia Dwork, Michael Kearns, Terrance Liu, Aaron Roth, Giuseppe Vietri, Zhiwei Steven Wu
      <br>
      <br>
      <a href="https://arxiv.org/abs/2308.16298">Publishing Wikipedia usage data with strong privacy guarantees</a>
      <br>
      Temilola Adeleye, Damien Desfontaines, Michael Hay, Isaac Johnson, Cléo Lemoisson, Ashwin Machanavajjhala, Tom Magerlein, Gabriele Modena, David Pujol, Daniel Simmons-Marengo, Hal Triedman
    </td>
  </tr>  

</table>

</div>


<div class="content box"> <h2>Context</h2>

<p>
Differential privacy (DP) is the leading framework for data analysis with rigorous privacy guarantees. In the last 15 years, it has transitioned from the realm of pure theory to large scale, real world deployments. The use of differential privacy by the U.S. Census Bureau and increasing industry adoption has increased its public profile and presents new questions for social scientists and policymakers.
</p>
<p>
Differential privacy is an inherently interdisciplinary field, drawing researchers from a variety of academic communities including machine learning, statistics, security, theoretical computer science, databases, and law. The combined effort across a broad spectrum of computer science is essential for differential privacy to realize its full potential. To this end, this workshop aims to stimulate discussion among participants about both the state-of-the-art in differential privacy and the future challenges that must be addressed to make differential privacy more practical.
</p>

<p>
Specific topics of interest for the workshop include (but are not limited to):
</p>
<ul>
<li>theory of differential privacy,</li>
<li>differential privacy and security,</li>
<li>privacy preserving machine learning,</li>
<li>differential privacy and statistics,</li>
<li>differential privacy and data analysis,</li>
<li>trade-offs between privacy protection and analytic utility,</li>
<li>differential privacy and surveys,</li>
<li>programming languages for differential privacy,</li>
<li>relaxations of the differential privacy definition,</li>
<li>differential privacy vs other privacy notions and methods,</li>
<li>experimental studies using differential privacy,</li>
<li>differential privacy implementations,</li>
<li>differential privacy and policy making,</li>
<li>applications of differential privacy.</li>
<li>reconstruction attacks and memorization</li>
</ul>

<p>The <a href="https://sites.harvard.edu/opendp-community-meeting-2023/">OpenDP Community Meeting 2023</a> will be taking place the same week as TPDP in Boston, on Friday, September 29. OpenDP will also be hosting a reception at 6pm on Thursday, September 28, after the conclusion of TPDP. We encourage participants to consider attending the community meeting!</p>

</div>

<div class="content box"> <h2>Accepted Papers</h2>


<p><b>Poster Session 1 </b></p>
    <ul>
        <li><a href="https://arxiv.org/abs/2301.13334">A Bias-Variance-Privacy Trilemma for Statistical Estimation</a></br>Gautam Kamath, Argyris Mouzakis, Matthew Regehr, Vikrant Singhal, Thomas Steinke, Jonathan Ullman</li>
	<li><a href="https://aps.arxiv.org/abs/2308.11110">A formal analysis of utility in differential privacy pipelines, using Kronecker products and quantitative information flow</a></br>Natasha Fernandes, Mario Alvim, Annabelle McIver, Carroll Morgan, Gabriel H. Nunes</li>
	<li>A Framework for Differential Privacy Against Timing Attacks</br>Zachary Ratliff, Salil Vadhan</li>
	<li>A Privacy-Friendly Approach to Data Valuation</br>Jiachen T. Wang, Yuqing Zhu, Yu-Xiang Wang, Ruoxi Jia, Prateek Mittal</li>
	<li><a href="https://arxiv.org/abs/2306.09666">A Smooth Binary Mechanism for Efficient Private Continual Observation</a></br>Joel Daniel Andersson, Rasmus Pagh</li>
        <li><a href="https://arxiv.org/abs/2306.13824">Adaptive Privacy Composition for Accuracy-first Mechanisms</a></br>Ryan Rogers, Gennady Samorodnitsky, Zhiwei Steven Wu, Aaditya Ramdas</li>
        <li><a href="https://arxiv.org/abs/2211.05006">Almost Tight Error Bounds on Differentially Private Continual Counting</a></br>Monika Henzinger, Jalaj Upadhyay, Sarvagya Upadhyay</li>
        <li><a href="https://arxiv.org/abs/2302.14517">Arbitrary Decisions are a Hidden Cost of Differentially Private Training</a></br>Bogdan Kulynych, Hsiang Hsu, Carmela Troncoso, Flavio P. Calmon</li>
        <li>Assessing Utility of Differential Privacy for RCTs</br>Soumya Mukherjee, Aratrika Mustafi, Aleksandra Slavkovi ć, Lars Vilhuber</li>
        <li>Better and Simpler Fingerprinting Lower Bounds for Differentially Private Estimation</br>Shyam Narayanan</li>
	<li><a href="https://arxiv.org/abs/2301.02457">Better Differentially Private Approximate Histograms and Heavy Hitters using the Misra-Gries Sketch</a></br>Christian Janos Lebeda, Jakub Tětek</li>
        <li><a href="https://arxiv.org/abs/2306.00920">Better Private Linear Regression Through Better Private Feature Selection</a></br>Travis Dick, Jennifer Gillenwater, Matthew Joseph</li>
        <li><a href="http://arxiv.org/abs/2308.12018">Bias-Aware Minimisation: Understanding and Mitigating Estimator Bias in Private SGD</a></br>Moritz Knolle, Robert Dorfman, Alexander Ziller, Daniel Rueckert, Georgios Kaissis</li>
        <li><a href="https://arxiv.org/abs/2307.03928">Bounding data reconstruction attacks with the hypothesis testing interpretation of differential privacy</a></br>Georgios Kaissis, Jamie Hayes, Alexander Ziller, Daniel Rueckert</li>
	<li><a href="https://arxiv.org/abs/2302.07225">Bounding Training Data Reconstruction in DP-SGD</a></br>Jamie Hayes, Saeed Mahloujifar, Borja Balle</li>
	<li>Certified private data release for sparse Lipschitz functions</br>Konstantin Donhauser, Johan Lokna, Amartya Sanyal, March Boedihardjo, Robert Hönig, Fanny Yang</li>
        <li><a href="https://arxiv.org/abs/2303.01256">Choosing Public Datasets for Private Machine Learning via Gradient Subspace Distance</a></br>Xin Gu, Gautam Kamath, Zhiwei Steven Wu</li>
        <li>Concurrent Composition for Interactive Differential Privacy with Adaptive Privacy-Loss Parameters</br>Samuel Haney, Michael Shoemate, Grace Tian, Salil Vadhan, Andrew Vyrros, Vicki Xu, Wanrong Zhang</li>
        <li><a href="https://arxiv.org/abs/2211.03128">Confidence-Ranked Reconstruction of Census Microdata from Published Statistics</a></br>Travis Dick, Cynthia Dwork, Michael Kearns, Terrance Liu, Aaron Roth, Giuseppe Vietri, Zhiwei Steven Wu</li>
        <li><a href="https://arxiv.org/abs/2212.06470">Considerations for Differentially Private Learning with Large-Scale Public Pretraining</a> </br>Florian Tramèr, Gautam Kamath, Nicholas Carlini</li>
        <li><a href="https://arxiv.org/abs/2306.07884">Continual Release of Differentially Private Synthetic Data</a></br>Mark Bun, Marco Gaboardi, Marcel Neunhoeffer, Wanrong Zhang</li>
        <li><a href="https://arxiv.org/abs/2306.06723#:~:text=Counting%20Distinct%20Elements%20in%20the%20Turnstile%20Model%20with%20Differential%20Privacy%20under%20Continual%20Observation,-Palak%20Jain%2C%20Iden&text=Privacy%20is%20a%20central%20challenge,updated%20to%20reflect%20changing%20data.">Counting Distinct Elements in the Turnstile Model with Differential Privacy under Continual Observation</a></br>Palak Jain, Iden Kalemaj, Sofya Raskhodnikova, Satchit Sivakumar, Adam Smith</li>
        <li><a href="papers/TPDP_2023_DPParamboot.pdf">Debiased Parametric Bootstrap Inference on Privatized Data</a></br>Zhanyu Wang, Jordan Awan</li>
	<li><a href="https://eprint.iacr.org/2023/971">Defining and Controlling Information Leakage in US Equities Trading</a></br>Arthur Américo, Allison Bishop, Paul Cesaretti, Garrison Grogan, Adam McKoy, Robert Moss, Lisa Oakley, Marcel Ribeiro, Mohammad Shokri</li>
	<li><a href="https://arxiv.org/abs/2307.07449">Differentially Private Clustering in Data Streams</a></br>Alessandro Epasto, Tamalika Mukherjee, Peilin Zhong</li>
        <li><a href="papers/DP-DME-bangalore.pdf">Differentially Private Distributed Mean Estimation with Malicious Security</a></br>Laasya Bangalore, Albert Cheu, Muthuramakrishnan Venkitasubramaniam</li>
        <li><a href="https://arxiv.org/abs/2307.11749">Differentially Private Heavy Hitter Detection using Federated Analytics</a></br>Karan Chadha, Junye Chen, John Duchi, Vitaly Feldman, Hanieh Hashemi, Omid Javidbakht, Audra McMillan, Kunal Talwar</li>
        <li><a href="https://arxiv.org/abs/2306.10428">Differentially Private Histogram, Predecessor, and Set Cardinality under Continual Observation</a></br>Monika Henzinger, A. R. Sricharan, Teresa Anna Steiner</li>
        <li><a href="https://arxiv.org/abs/2306.06076">Differentially Private Image Classification by Learning Priors from Random Processes</a> </br> Xinyu Tang, Ashwinee Panda, Vikash Sehwag, Prateek Mittal</li>
        <li><a href="https://arxiv.org/abs/2305.13440">Differentially Private Medians and Interior Points for Non-Pathological Data</a></br>Maryam Aliakbarpour, Rose Silver, Thomas Steinke, Jonathan Ullman</li>
        <li><a href="https://arxiv.org/abs/2302.04972">Differentially Private Optimization for Smooth Nonconvex ERM</a></br>Changyu Gao, Stephen J. Wright</li>
        <li>Differentially Private Resource Allocation</br>Joann Qiongna Chen, Tianhao Wang, Zhikun Zhang, Yang Zhang, Somesh Jha, Zhou Li</li>
        <li>Differentially Private Reward Estimation from Preference Based Feedback</br>Sayak Ray Chowdhury, Xingyu Zhou</li>
        <li>Differentially Private Secure Multiplication: Hiding Information in the Rubble of Noise</br>Viveck R. Cadambe, Ateet Devulapalli, Haewon Jeong, Flavio Calmon</li>
        <li>Differentially Private Vertical Federated Learning Primitives<br>Vincent Cohen-Addad, Praneeth Kacham, Vahab Mirrokni, Peilin Zhong</li>
	<li>Distributed HDMM: Optimal Accuracy without a Trusted Curator</br>Ratang W. Sedimo, Ivoline C. Ngong, Joseph P. Near</li>
        <li><a href="https://arxiv.org/abs/2301.01998">DP-SIPS: A simpler, more scalable mechanism for differentially private partition selection</a></br>Marika Swanberg, Damien Desfontaines, Samuel Haney</li>
        <li><a href="https://arxiv.org/abs/2307.10430">DP-TBART: A Transformer-based Autoregressive Model for Differentially Private Tabular Data Generation</a></br>Rodrigo Castellon, Achintya Gopal, Brian Bloniarz, David Rosenberg</li>
        <li>EPSILON 10 AND THE NIST CRC DEIDENTIFIED DATA ARCHIVE</br>Christine Task, Karan Bhagat, Dhruv Kapur, Garry Howarth</li>
	<li>The Saddle-Point Method in Differential Privacy</br>Wael Alghamdi, Juan Felipe Gomez, Shahab Asoodeh, Flavio P. Calmon, Oliver Kosut, Lalitha Sankar</li>
</ul>

<p><b>Poster Session 2  </b></p>      
<ul>
	<li><a href="https://arxiv.org/abs/2306.04924">Exact Optimality of Communication-Privacy-Utility Tradeoffs in Distributed Mean Estimation</a></br>Berivan Isik, Wei-Ning Chen, Ayfer Ozgur, Tsachy Weissman, Albert No</li>
	<li><a href="https://arxiv.org/abs/2306.04444">Fast Optimal Locally Private Mean Estimation via Random Projections</a></br>Hilal Asi, Vitaly Feldman, Jelani Nelson, Huy L. Nguyen, Kunal Talwar</li>
	<li><a href="https://arxiv.org/abs/2301.12250">Fast, Sample-Efficient, Affine-Invariant Private Mean and Covariance Estimation for Subgaussian Distributions</a></br>Gavin Brown, Samuel B. Hopkins, Adam Smith</li>
        <li><a href="https://arxiv.org/abs/2305.13209">Faster Differentially Private Convex Optimization via Second-Order Methods</a></br>Arun Ganesh, Mahdi Haghifam, Thomas Steinke, Abhradeep Thakurta</li>
        <li>Federated Experiment Design under Distributed Differential Privacy</br>Wei-Ning Chen, Akash Bharadwaj, Graham Cormode, Peter Romov, Ayfer Özgür</li>
        <li><a href="https://arxiv.org/abs/2306.05275">Federated Linear Contextual Bandits with User-level Differential Privacy</a></br>Ruiquan Huang, Huanyu Zhang, Luca Melis, Milan Shen, Meisam Hajzinia, Jing Yang</li>
        <li>Formal Privacy Framework and Mechanism Design for Establishment Data</br>Kaitlyn Dowden, John Durrel, Dan Kifer, Prottay Protivash, Aleksandra Slavković, Daniell Toth, and Danfeng Zhang</li>
        <li><a href="https://arxiv.org/abs/2302.01855">From Robustness to Privacy and Back</a></br>Hilal Asi, Jonathan Ullman, Lydia Zakynthinou</li>
        <li>From Theory to Implementation: How Open-Source DP Libraries Shape Mental Models of Privacy Concepts</br>Patrick Song, Jayshree Sarathy, Michael Shoemate, Salil Vadhan</li>
        <li>General Gaussian Noise Mechanisms and Their Optimality for Unbiased Mean Estimation</br>Aleksandar Nikolov, Haohua Tang</li>
        <li><a href="https://arxiv.org/abs/2306.03962">How to make semi-private learning effective</a></br>Francesco Pinto, Yaxi Hu, Fanny Yang, Amartya Sanyal</li>
        <li><a href="https://arxiv.org/abs/2210.03831">How to Make Your Approximation Algorithm Private: A Black-Box Differentially-Private Transformation for Tunable Approximation Algorithms of Functions with Low Sensitivity</a></br>Jeremiah Blocki, Elena Grigorescu, Tamalika Mukherjee, Samson Zhou</li>
        <li><a href="https://arxiv.org/abs/2303.03451">Improved Differentially Private Regression via Gradient Boosting</a></br>Shuai Tang, Sergul Aydore, Michael Kearns, Saeyoung Rho, Aaron Roth, Yichen Wang, Yu-Xiang Wang, Zhiwei Steven Wu</li>
	<li>Improving the Privacy and Practicality of Objective Perturbation</br>Rachel Redberg, Antti Koskela, Yu-Xiang Wang</li>
        <li>Initialization Matters: Privacy-utility analysis of Overparameterized Neural Networks</br>Jiayuan Ye, Zhenyu Zhu, Fanghui Liu, Reza Shokri, Volkan Cevher</li>
        <li>Interactive Proofs For Differential Privacy</br>Ari Biswas, Graham Cormode</li>
        <li>k-Means Clustering with Distance-Based Privacy</br>Alessandro Epasto, Vahab Mirrokni, Shyam Narayanan, Peilin Zhong</li>
        <li>Leveraging Public Representation Learning for Provable Private Transfer Learning</br>Pratiksha Thaker, Amrith Setlur, Virginia Smith, Zhiwei Steven Wu</li>
        <li>Local Differential Privacy with Entropic Wasserstein Distance</br>Daria Reshetova, Wei-Ning Chen, Ayfer Özgür</li>
        <li><a href="https://dl.acm.org/doi/abs/10.14778/3594512.3594529">Longshot: Indexing Growing Databases using MPC and Differential Privacy</a></br>Yanping Zhang, Johes Bater, Kartik Nayak, Ashwin Machanavajjhala</li>
        <li>Measure-Observe-(Re)measure: An Interactive Paradigm for Differentially-Private Exploratory Analysis</br>Priyanka Nanayakkara, Hyeok Kim, Yifan Wu, Ali Sarvghad, Narges Mahyar, Gerome Miklau, Jessica Hullman</li>
	<li>Measuring Local Differential Privacy of Gradient Randomized Response</br>Marin Matsumoto, Tsubasa Takahashi, Seng Pei Liew, Masato Oguchi</li>
        <li>Models Matter: Setting Accurate Privacy Expectations for Local and Central Differential Privacy</br>Mary Anne Smart, Priyanka Nanayakkara, Rachel Cummings, Gabriel Kaptchuk, Elissa M. Redmiles</li>
        <li>Neural Collapse meets Differential Privacy: Curious behaviors of NoisySGD with Near-Perfect Representation Learning</br>Yu-Xiang Wang, Chendi Wang, Yuqing Zhu, Weijie J. Su</li>
        <li><a href="https://arxiv.org/abs/2304.05890">Node-Differentially Private Estimation of the Number of Connected Components</a></br>Iden Kalemaj, Sofya Raskhodnikova, Adam Smith, Charalampos E. Tsourakakis</li>
        <li>On Computing Pairwise Statistics with Local Differential Privacy</br>Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Adam Sealfon</li>
        <li><a href="https://arxiv.org/abs/2302.13945">On Differentially Private Federated Linear Contextual Bandits</a></br>Xingyu Zhou, Sayak Ray Chowdhury</li>
        <li><a href="https://arxiv.org/abs/2306.12549">On Differentially Private Sampling from Gaussian and Product Distributions</a></br>Badih Ghazi, Xiao Hu, Ravi Kumar, Pasin Manurangsi</li>
        <li><a href="https://arxiv.org/abs/2306.15056#:~:text=Abstract%3A%20Differential%20Privacy%20(DP),accuracy%20or%20higher%20sample%20complexity.">Optimal Differentially Private Learning with Public Data</a></br>Andrew Lowy, Zeman Li, Tianjian Huang, Meisam Razaviyayn</li>
	<li>Optimal group privacy for DP-SGD</br>Saeed Mahloujifar, Alex Sblayrolles, Graham Cormode, Somesh Jha</li>
        <li>Optimal Multidimensional Differentially Private Mechanisms in the Large-Composition Regime</br>Wael Alghamdi, Shahab Asoodeh, Flavio P. Calmon, Juan Felipe Gomez, Oliver Kosut, Lalitha Sankar</li>
        <li>Per-record Differential Privacy: Modeling Dependence Between Individual Privacy Loss and Confidential Records</br>Jeremy Seeman, William Sexton, David Pujol, Ashwin Machanavajjhala</li>
        <li>Per-User Histograms In The Shuffle Model</br>Aashish Kolluri, Jacob Imola, Amrita Roy Chowdhury</li>    
        <li><a href="https://arxiv.org/abs/2304.01541">Privacy Amplification via Compression: Achieving the Optimal Privacy-Accuracy-Communication Trade-off in Distributed Mean Estimation</a></br>Wei-Ning Chen, Dan Song, Ayfer Ozgur, Peter Kairouz</li>
	<li><a href="https://arxiv.org/abs/2206.03151#:~:text=We%20study%20a%20protocol%20for,assumptions%20beyond%20a%20trusted%20shuffler.">Privacy amplification via shuffled check-in</a></br>Seng Pei Liew, Satoshi Hasegawa, Tsubasa Takahashi</li>    
        <li><a href="https://arxiv.org/abs/2305.08846">Privacy Auditing with One (1) Training Run</a></br>Thomas Steinke, Milad Nasr, Matthew Jagielski</li>
        <li><a href="https://arxiv.org/abs/2305.09903">Privacy Loss of Noisy-SGD Might Converge Even for Non-Convex Losses</a></br>Shahab Asoodeh, Mario Diaz</li>
        <li>Private Algorithms with Private Predictions</br>Kareem Amin, Travis Dick, Mikhail Khodak, Sergei Vassilvitskii</li>
	<li><a href="https://arxiv.org/abs/2308.06239">Private distribution learning with public data: The view from sample compression</a> </br> Shai Ben-David, Alex Bie, Clément L. Canonne, Gautam Kamath, Vikrant Singhal </li>
        <li><a href="https://arxiv.org/abs/2306.08842">ViP: A Differentially Private Foundation Model for Computer Vision</a></br>Yaodong Yu, Maziar Sanjabi, Yi Ma, Kamalika Chaudhuri, Chuan Guo</li>
	<li><a href="https://arxiv.org/abs/2206.10525">PRIVIC: A privacy-preserving method for incremental collection of location data</a></br>Sayan Biswas, Catuscia Palamidessi</li>
</ul>

<p><b>Poster Session 3	</b></p>
<ul>
      <li>Title TBA</br>Nico Manzonelli, Wanrong Zhang, Salil Vadhan</li>
      <li>Evaluating the Usability of Differential Privacy Tools with Data Scientists</br>Ivoline C. Ngong, Brad Stenger, Joseph P. Near, Yuanyuan Feng</li>
      <li><a href="https://arxiv.org/abs/2305.09579#:~:text=A%20private%20learner%20is%20trained,al.%2C%20FOCS%202008%5D.">Private Everlasting Prediction</a>
      </br>Moni Naor, Kobbi Nissim, Uri Stemmer, Chao Yan
	<li><a href="https://arxiv.org/abs/2306.09396">Private Federated Frequency Estimation: Adapting to the Hardness of the Instance</a></br>Jingfeng Wu, Wennan Zhu, Peter Kairouz, Vladimir Braverman</li>
        <li><a href="https://arxiv.org/abs/2302.02936">Private GANs, Revisited</a> </br> Alex Bie, Gautam Kamath, Guojun Zhang</li>
        <li><a href="https://arxiv.org/abs/2210.13537">Private Online Prediction from Experts: Separations and Faster Rates</a></br>Hilal Asi, Vitaly Feldman, Tomer Koren, Kunal Talwar</li>
        <li><a href="https://eprint.iacr.org/2023/787">Private Proof-of-Stake Blockchains using Differentially-Private Stake Distortion</a></br>Chenghong Wang, David Pujol, Kartik Nayak, Ashwin Machanavajjhala</li>
	<li><a href="https://arxiv.org/abs/2209.07403">Private Stochastic Optimization with Large Worst-Case Lipschitz Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses</a></br>Andrew Lowy, Meisam Razaviyayn</li>
	<li>Private Treatment Assignment for Causal Experiments</br>Jeremy Seeman</li>
        <li>Publishing Wikipedia usage data with strong privacy guarantees</br>Temilola Adeleye, Damien Desfontaines, Michael Hay, Isaac Johnson, Cléo Lemoisson, Ashwin Machanavajjhala, Tom Magerlein, Gabriele Modena, David Pujol, Daniel Simmons-Marengo, Hal Triedman</li>
        <li><a href="https://arxiv.org/abs/2305.17634">Pure-DP Aggregation in the Shuffle Model: Error-Optimal and Communication-Efficient</a></br>Badih Ghazi, Ravi Kumar, Pasin Manurangsi</li>
        <li>Quantifying Uncertainty of Unsupported Linear Queries for Private Query Release</br>Brett Mullins, Gerome Miklau, Daniel Sheldon</li>
        <li><a href="https://arxiv.org/abs/2308.03735">Randomized algorithms for precise measurement of differentially-private, personalized recommendations</a></br>Allegra Laro, Yanqing Chen, Hao He, Babak Aghazadeh</li>
	<li>Removing Clipping Error in Differentially Private SGD: An Error-Feedback Approach</br>Xinwei Zhang, Zhiqi Bu, Zhiwei Steven Wu, Mingyi Hong</li>
        <li>Rethinking Benchmarks for Private Image Classification </br> Sabrina Mokhtari, Shubhankar Mohapatra, Sara Kodeiri, Florian Tramèr, Gautam Kamath</li>
        <li><a href="https://arxiv.org/abs/2309.01597">Revealing the True Cost of Local Privacy: An Auditing Perspective</a></br>Héber H. Arcolezi, Sébastien Gambs</li>
        <li><a href="https://arxiv.org/abs/2212.05015">Robustness Implies Privacy in Statistical Estimation</a> </br> Samuel B. Hopkins, Gautam Kamath, Mahbod Majid, Shyam Narayanan</li>
        <li><a href="https://arxiv.org/abs/2307.03694#:~:text=Membership%20inference%20attacks%20are%20designed,as%20a%20hypothesis%20testing%20problem.">Scalable Membership Inference Attacks via Quantile Regression</a></br>Martin Bertran, Shuai Tang, Michael Kearns, Jamie Morgenstern, Aaron Roth, Zhiwei Steven Wu</li>
        <li>Schrödinger Mechanisms: Optimal Differential Privacy Mechanisms for Small Sensitivity</br>Wael Alghamdi, Shahab Asoodeh, Flavio P. Calmon, Juan Felipe Gomez, Oliver Kosut, Lalitha Sankar</li>
        <li><a href="https://arxiv.org/abs/2301.03566">Simple Binary Hypothesis Testing under Local Differential Privacy and Communication Constraints</a></br>Ankit Pensia, Amir R. Asadi, Varun Jog, Po-Ling Loh</li>
        <li><a href="https://arxiv.org/abs/2307.07604">Smooth Lower Bounds for Differentially Private Algorithms via Padding-and-Permuting Fingerprinting Codes</a></br>Naty Peter, Eliad Tsfadia, Jonathan Ullman</li>
        <li><a href="https://arxiv.org/abs/2303.12921">Stability is Stable: Connections between Replicability, Privacy, and Adaptive Generalization</a></br>Mark Bun, Marco Gaboardi, Max Hopkins, Russell Impagliazzo, Rex Lei, Toniann Pitassi, Satchit Sivakumar, Jessica Sorrell</li>
        <li><a href="https://arxiv.org/abs/2210.08781">Stochastic Differentially Private and Fair Learning</a></br>Andrew Lowy, Devansh Gupta, Meisam Razaviyayn</li>
	<li><a href="https://arxiv.org/abs/2308.12876">The Impact of De-Identification on Single-Year-of-Age Counts in the U.S. Census</a></br>Sarah Radway, Miranda Christ</li>
	<li><a href="https://arxiv.org/abs/2307.11106">The importance of feature preprocessing for differentially private linear optimization</a></br>Ziteng Sun, Ananda Theertha Suresh, Aditya Krishna Menon</li>
	<li><a href="https://arxiv.org/abs/2302.11044">The Target-Charging Technique for Privacy Accounting across Interactive Computations</a></br>Edith Cohen, Xin Lyu</li>
        <li>Thompson Sampling Itself is Differentially Private</br>Tingting Ou, Marco Avella Medina, Rachel Cummings</li>
        <li><a href="https://arxiv.org/abs/2309.00886 ">Tight Bounds for Machine Unlearning via Differential Privacy</a></br>Yiyang Huang, Clément L. Canonne</li>
        <li><a href="https://arxiv.org/abs/2301.13347">Tight Data Access Bounds for Private Top-k Selection</a></br>Hao Wu, Olga Ohrimenko, Anthony Wirth</li>
        <li>Time-Aware Projections: Truly Node-Private Graph Statistics under Continual Observation</br>Palak Jain, Adam Smith, Connor Wagaman</li>
        <li><a href="https://arxiv.org/abs/2306.01181">TMI! Finetuned Models Spill Secrets from Pretraining</a></br>John Abascal, Stanley Wu, Alina Oprea, Jonathan Ullman</li>
	<li><a href="https://arxiv.org/abs/2305.02263">Triangle Counting with Local Edge Differential Privacy</a></br>Talya Eden, Quanquan C. Liu, Sofya Raskhodnikova, Adam Smith</li>
        <li><a href="https://arxiv.org/abs/2212.04133">Tumult Analytics: a Robust, Easy-to-use, Scalable, and Expressive Framework for Differential Privacy</a></br>Skye Berghel, Philip Bohannon, Damien Desfontaines, Charles Estes, Sam Haney, Luke Hartman, Michael Hay, Ashwin Machanavajjhala, Tom Magerlein, Gerome Miklau, Amritha Pai, William Sexton, Ruchit Shrestha</li>
        <li>Uncertainty Quantification with User-Level DP</br>Dj Dvijotham Krishnamurthy, Georgina Evans, Peter Kairouz, Ryan McKenna, Sewoong Oh, Abhradeep Guha Thakurta</li>
        <li><a href="https://arxiv.org/abs/2305.18447">Unleashing the Power of Randomization in Auditing Differentially Private ML</a></br>Krishna Pillutla, Galen Andrew, Peter Kairouz, H. Brendan McMahan, Alina Oprea, Sewoong Oh</li>
	<li>User-Level Differential Privacy With Few Examples Per User</br>Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Raghu Meka, Chiyuan Zhan</li>
        <li><a href="https://arxiv.org/abs/2303.00738">What Are the Chances? Explaining the Epsilon Parameter in Differential Privacy</a></br>Priyanka Nanayakkara, Mary Anne Smart, Rachel Cummings, Gabriel Kaptchuk, Elissa Redmiles</li>
	<li>Why is it Gaussian? Exploring the Generalized Gaussian Mechanism for Private Machine Learning</br>Roy Rinberg, Ilia Shumailov, Rachel Cummings, Nicolas Papernot</li>
    </ul>

<p><b>Virtual Posters</b></p>
<ul>
	<li><a href="https://arxiv.org/abs/2306.00920">Better Private Linear Regression Through Better Private Feature Selection</a></br>Travis Dick, Jennifer Gillenwater, Matthew Joseph</li>
</ul>

</div>

<div class="content box">
<h2 id="submission">Submission</h2>

<p>
  The goal of TPDP is to stimulate the discussion on the relevance of differentially private data analyses in practice. For this reason, we seek contributions from different research areas of computer science and statistics.
</p>

<p>
Authors are invited to submit a short abstract (4 pages maximum, with unlimited references and appendices (only read at reviewer's discretion)) of their work.
Submissions are single-blind (non-anonymized), and there is no prescribed style file (though authors should be considerate of reviewers in their selection).
</p>

<p>
  Submissions will undergo a lightweight review process and will be judged on originality, relevance, interest and clarity. Submission should describe novel work or work that has already appeared elsewhere but that can stimulate the discussion between different communities at the workshop. Accepted abstracts will be presented at the workshop either as a talk or a poster.
</p>

<p>
  The workshop will not have formal proceedings and is not intended to preclude later publication at another venue. In-person attendance is encouraged, though there will be some limited means for work by non-attending authors to be featured at TPDP 2023.
</p>

<p>
  Selected papers from the workshop will be invited to submit a full version of their work for publication in a <a href="https://journalprivacyconfidentiality.org/index.php/jpc/tpdp">special issue</a> of the <a href="https://journalprivacyconfidentiality.org/index.php/jpc">Journal of Privacy and Confidentiality</a>.
</p>

<p>
Call for Papers: <a href="2023-TPDP-CfP.pdf">PDF</a>
</p>
</div>

<div class="side box">
<h2>Invited Speakers</h2>
<ul>
  <li>
    <a href="https://sites.psu.edu/sesa/">Aleksandra Slavković</a><br>
    Penn State University
  </li>

  <li>
    <a href="https://pasin30055.github.io">Pasin Manurangsi</a> <br>
    Google Research
  </li>

  <li > <a href="https://wanrongz.github.io">Wanrong Zhang</a> <br>
    Harvard University
  </li>
</ul>
</div>

<div class="side box">
<h2 id="corpsponsor">Corporate Sponsors</h2>

<p>
We are very grateful to our sponsors whose generosity has been critical to the continued success of the workshop. For information about sponsorship opportunities, please contact us at <a href="mailto:tpdp2023@gmail.com">tpdp2023@gmail.com</a>.
</p>

<h3 class="small-heading">Gold Tier Sponsors</h3>

<div class="image-with-text">
  <p><a href="https://machinelearning.apple.com">Apple</a></p>
  <img src="apple_logo" alt="Apple logo" width="80">
</div>

<h3 class="small-heading">Silver Tier Sponsors</h3>

<p><a href="https://www.bu.edu/cds-faculty/">Boston University Faculty of Computing & Data Sciences</a></p>
<div class="image-with-text">
  <img src="BU" alt="BU logo" width="120">
</div>

<p><a href="https://www.bu.edu/hic/">Rafik B. Hariri Institute for Computing and Computational Science & Engineering</a></p>  
<div class="image-with-text"> 
	<img src="hariri.pdf" alt="HIC Logo" width="300">
</div>

<h3 class="small-heading">Bronze Tier Sponsors</h3>

<div class="image-with-text">
  <p><a href="https://www.tmlt.io">Tumult Labs</a></p>
  <img src="Tumult_Labs" alt="Tumult logo" width="150">
</div>

<div class="image-with-text">
  <p><a href="https://www.dpella.io">DPella</a></p>
  <img src="DPella" alt="DPella logo" width="150">
</div>

</div>

<div class="side box">
  <h2>Registration</h2>
<dl>
Register for TPDP 2023 
<a href="https://forms.gle/XCNqz1FctrTH5bTWA">here</a>!
  </dl>
<p>
</p>
</div>


<div class="side box">
  <h2>Important Dates</h2>
  <dl>
    <dt>Abstract Submission</dt>
    <dd>July 7, 2023 (AoE)</dd>
    <dt>Notification</dt>
    <dd>August 11, 2023</dd>
    <dt>Workshop</dt>
    <dd>September 27-28, 2023</dd>
  </dl>
</div>

<div class="side box">
  <h2>Submission website</h2>
<dl>
<a href="https://hcrp.cs.uchicago.edu">https://hcrp.cs.uchicago.edu</a>
  </dl>
<p>
For concerns regarding submissions, please contact <a href="mailto:tpdp2023@gmail.com">tpdp2023@gmail.com</a>.
</p>
</div>


<div class="side box">
  <h2>Organizing and Program Committee</h2>
  <ul>
    <li class="pc">
      <a href="https://aloni.net">Aloni Cohen</a> (co-chair)<br>
      University of Chicago
    </li>
    <li class="pc">
      <a href="https://audramarymcmillan.wixsite.com/mysite">Audra McMillan</a> (co-chair)<br>
      Apple
    </li>
    <li class="pc">
    <a href="https://www.mit.edu/~maryama/">Maryam Aliakbarpour</a><br>
      Rice University
    </li>
    <li class="pc">
    <a href="https://web.stanford.edu/~asi/">Hilal Asi</a><br>
      Apple
    </li>
    <li class="pc">
    <a href="https://cs-people.bu.edu/grbrown/">Gavin Brown</a><br>
      Boston University
    </li>
    <li class="pc">
    <a href="https://ccanonne.github.io">Clément Canonne</a><br>
      University of Sydney
    </li>
    <li class="pc">
    <a href="https://sites.google.com/wisc.edu/amrita-roy-chowdhury/">Amrita Roy Chowdhury</a><br>
      UC San Diego
    </li>
    <li class="pc">
    <a href="https://csrcl.huji.ac.il/people/ayelet-gordon-tapiero">Ayelet Gordon-Tapiero</a><br>
      Georgetown University
    </li>
    <li class="pc">
    <a href="https://cs.colgate.edu/~mhay/">Michael Hay</a><br>
      Colgate University and Tumult Labs
    </li>
    <li class="pc">
    <a href="https://hona.kr">James Honaker</a><br>
      Anonym
    </li>
    <li class="pc">
    <a href="https://jagielski.github.io">Matthew Jagielski</a><br>
      Google Brain
    </li>
    <li class="pc">
    <a href="https://www.lxuechen.com">Xuechen Li</a><br>
      Stanford
    </li>
    <li class="pc">
    <a href="https://daogaoliu.github.io">Daogao Liu</a><br>
      University of Washington
    </li>
    <li class="pc">
    <a href="https://csaws.cs.technion.ac.il/~shaymrn/">Shay Moran</a><br>
      Technion
    </li>
    <li class="pc">
    <a href="https://www.uvm.edu/~jnear/">Joe Near</a><br>
      University of Vermont
    </li>
    <li class="pc">
    <a href="https://www.cs.toronto.edu/~anikolov/">Aleksandar Nikolov</a><br>
      University of Toronto
    </li>
    <li class="pc">
    <a href="https://homes.cs.washington.edu/~sewoong/">Sewoong Oh</a><br>
      University of Washington
    </li>
    <li class="pc">
    <a href="https://oohrimenko.github.io">Olya Ohrienko</a><br>
      University of Melbourne
    </li>
    <li class="pc">
    <a href="https://www.personal.psu.edu/mlr36/">Matthew Reimerr</a><br>
      Penn State
    </li>
    <li class="pc">
    <a href="https://www.linkedin.com/in/rrogers386">Ryan Rogers</a><br>
      LinkedIn
    </li>
    <li class="pc">
    <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a><br>
      University of Pennsylvania
    </li>
    <li class="pc">
    <a href="https://www.cse.chalmers.se/~russo/">Alejandro Russo</a><br>
      Chalmers and DPella
    </li>
    <li class="pc">
    <a href="https://scholar.harvard.edu/jsarathy/home">Jayshree Sarathy</a><br>
      Harvard
    </li>
    <li class="pc">
    <a href="https://asealfon.github.io">Adam Sealfon</a><br>
      Google Research
    </li>
    <li class="pc">
    <a href="https://personal.psu.edu/jhs5496/">Jeremy Seeman</a><br>
      University of Michigan
    </li>
    <li class="pc">
    <a href="https://www.eng.biu.ac.il/sheffeo1/">Or Sheffet</a><br>
      Bar-Ilan University
    </li>
    <li class="pc">
    <a href="https://www.vikrantsinghal.com">Vikrant Singhal</a><br>
      University of Waterloo
    </li>
    <li class="pc">
    <a href="https://cs-people.bu.edu/ads22/">Adam Smith</a><br>
      Boston University
    </li>
    <li class="pc">
    <a href="https://sites.google.com/bu.edu/marika">Marika Swanberg</a><br>
      Boston University
    </li>
    <li class="pc">
    <a href="http://kunaltalwar.org">Kunal Talwar</a><br>
      Apple
    </li>
    <li class="pc">
    <a href="https://knexusresearch.com/team_members/dr-christine-task/">Christine Task</a><br>
      Knexus Research
    </li>
    <li class="pc">
    <a href="https://tianhao.wang">Tianhao Wang</a><br>
      University of Virginia
    </li>
    <li class="pc">
    <a href="https://cyber.harvard.edu/people/awood">Alexandra Wood</a><br>
      Harvard
    </li>
    <li class="pc">
    <a href="https://linjunz.github.io">Linjun Zhang</a><br>
      Rutgers
    </li>
    <li class="pc">
    <a href="https://wanrongz.github.io">Wanrong Zhang</a><br>
      Harvard
    </li>
    <li class="pc">
    <a href="https://jeremy43.github.io">Yuqing Zhu</a><br>
      UC Santa Barbara
    </li>
    <li class="pc">
    <a href="http://www.juba-ziani.com">Juba Ziani</a><br>
      Georgia Tech
    </li>
  </ul>
</div>


<div id="bg_descr">
</div>

</body></html>
