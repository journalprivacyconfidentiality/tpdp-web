<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
            "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width">
  <title>TPDP 2024 – Theory and Practice of Differential Privacy</title>

  <link href="style.css" type="text/css" rel='stylesheet'>
  <link rel='stylesheet' media='screen and (max-width: 750px)'
  href='narrow.css'>

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<meta property="og:image" content="https://tpdp.journalprivacyconfidentiality.org/android-chrome-512x512.png">
<meta property="og:image:type" content="image/png">
<meta property="og:image:width" content="512">
<meta property="og:image:height" content="512">

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}})
</script>
</head>

<style>
  .image-with-text {
    display: flex;
    align-items: center;
  }

  .image-with-text p {
    margin-right: 10px;
  }
</style>

<body>

<div id="header">
  <h1>TPDP 2024 - Theory and Practice of Differential Privacy</h1>
  <h2>Boston - August 20-21, 2024 
    <br>
  </h2>
</div>

<div class="program box">
  <h2>Workshop Information</h2>
<p>
TPDP 2024 will take place on August 20 and 21 at the <a href="https://seas.harvard.edu/about-us/visit-us/allston/science-engineering-complex">Harvard University Science and Engineering Complex (SEC)</a>. TPDP is co-located with the <a href="https://sites.harvard.edu/opendp/">2024 OpenDP Community Meeting</a>, happening on August 22 and 23. We hope you will attend both!
</p>

<p>
  <b>Registration:</b> Registration for TPDP 2024 is free. Please <a href="https://forms.gle/Q9S2sk1H6mMqCdmq5">click here</a> or use the link in the sidebar to register for the workshop, and don't forget to register for the <a href="https://sites.harvard.edu/opendp/">OpenDP Community Meeting</a> (also free) too!
</p>

<p>
  <b>Logistics:</b> The workshop will be held at the <a href="https://seas.harvard.edu/about-us/visit-us/allston/science-engineering-complex">Harvard University Science and Engineering Complex (SEC)</a>. The OpenDP Community Meeting page has a helpful <a href="https://sites.harvard.edu/opendp/events/2024-opendp-community-meeting/resources/where-to-stay/">list of nearby hotels</a>.
</p>

<h2>Program</h2>

<ul>
<li><b>Talks</b> will be held in the <b>Winokur Family Hall</b> on the first floor of the SEC building</li>
<li><b>Poster sessions, breaks, and lunch</b> will be held in the <b>West Atrium</b> on the first floor of the SEC building</li>
<li><a href="https://sites.harvard.edu/opendp/events/2024-opendp-community-meeting/resources/">Click here</a> for an interior map of the SEC building</a>
</ul>

<table  style="padding:15px; column-gap:1000px">

<p><b>Tuesday, August 20</b></p>

<tr>
<td style="width: 100px;">
9:00-9:05
</td>
<td></td>
<td>
Welcome
<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
9:05-9:50
</td>
<td></td>
<td>

<button type="button" class="collapsible">Keynote: Robustness against Poisoning under LDP<br>
<i>Amrita Roy Chowdhury (Invited Speaker)</i></button>
<div class="abstract">
  <p>Local Differential Privacy (LDP) has become increasingly popular in recent years. However, with its
widespread adoption, it is crucial to examine the potential vulnerabilities. The distributed nature of LDP exposes
it to poisoning attacks, where an adversary can realistically inject fake clients that submit poisoned or malformed
data. In this talk, we will explore solutions to provide provable robustness against such attacks. Specifically, we
will analyze how LDP protocols possess a unique characteristic that distinguishes them from non-private ones —
the clear separation between the input and the final response (obtained after randomization). This separation
provides adversaries with two distinct opportunities to tamper with the data. We will discuss strategies to
mitigate both types of tampering by applying them in real-world settings and exploring the associated
challenges.</p>
<p><a href="https://sites.google.com/wisc.edu/amrita-roy-chowdhury/">Amrita Roy Chowdhury's website</a></p>
</div>

<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
9:50-10:35
</td>
<td></td>
<td>

<button type="button" class="collapsible">How Private are DP-SGD Implementations?<br><i>Lynn Chua, Badih Ghazi, <b>Pritish Kamath</b>, Ravi Kumar, Pasin Manurangsi, Amer Sinha, Chiyuan Zhang</i></button>
<div class="abstract">
  <p>We demonstrate a substantial gap between the privacy guarantees of the Adaptive Batch Linear Queries (ABLQ) mechanism under different types of batch sampling: (i) Shuffling, and (ii) Poisson subsampling; the typical analysis of Differentially Private Stochastic Gradient Descent (DP-SGD) follows by interpreting it as a post-processing of ABLQ. While shuffling-based DP-SGD is more commonly used in practical implementations, it has not been amenable to easy privacy analysis, either analytically or even numerically. On the other hand, Poisson subsampling-based DP-SGD is challenging to scalably implement, but has a well-understood privacy analysis, with multiple open-source numerically tight privacy accountants available. This has led to a common practice of using shuffling-based DP-SGD in practice, but using the privacy analysis for the corresponding Poisson subsampling version. Our result shows that there can be a substantial gap between the privacy analysis when using the two types of batch sampling, and thus advises caution in reporting privacy parameters for DP-SGD.</p>
<p><a href="https://arxiv.org/abs/2403.17673">Full paper</a></p>
</div>

<button type="button" class="collapsible">Lower Bounds for Differential Privacy Under Continual Observation and its Implications<br><i>Edith Cohen, <b>Xin Lyu</b>, Jelani Nelson, Tamás Sarlós, Uri Stemmer</i></button>
<div class="abstract">
  <p>We study differential privacy under continual observation and prove new lower bounds for private online counters. Specifically, we show that, over a stream of length T, any (eps, delta)-DP counter must incur an additive error of Omega(log T), even if the stream contains at most log(T) increments. For the offline version of the problem (i.e., releasing prefix sums of a given array), there is an upper bound for sparse stream under approximate DP with O(log^* T) additive error. Our result thus separates the online and offline versions of the problem. Based on the new proof, we derive several consequences for other online tasks, including a new lower bound for answering online threshold queries, and a lower bound for differentially-private online learning.</p>
</div>

<button type="button" class="collapsible">Efficient and Near-Optimal Noise Generation for Streaming Differential Privacy<br><i>Krishnamurthy (Dj) Dvijootham, H. Brendan McMahan, Krishna Pillutla, <b>Thomas Steinke</b>, Abhradeep Thakkurta, Krishna Pillutla</i></button>
<div class="abstract">
  <p>In the task of differentially private (DP) continual counting, we receive a stream of increments and our goal is to output an approximate running total of these increments, without revealing too much about any specific increment. Despite its simplicity, differentially private continual counting has attracted significant attention both in theory and in practice. Existing algorithms for differentially private continual counting are either inefficient in terms of their space usage or add an excessive amount of noise, inducing suboptimal utility.</p>

<p>The most practical DP continual counting algorithms add carefully correlated Gaussian noise to the values. The task of choosing the covariance for this noise can be expressed in terms of factoring the lower-triangular matrix of ones (which computes prefix sums). We present two approaches from this class (for different parameter regimes) that achieve near-optimal utility for DP continual counting and only require logarithmic or polylogarithmic space (and time).</p>
</div>

</td>
</tr>

<tr>
<td style="width: 100px;">
10:35-11:00
</td>
<td></td>
<td>
Break<br>
<i>Thanks to Silver level sponsors dpella and Tumult Labs!</i>
<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
11:00-12:30
</td>
<td></td>
<td>
<a href="#poster1">Poster Session #1</a>
<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
12:30-1:30
</td>
<td></td>
<td>
Lunch (provided)<br>
<i>Thanks to Platinum level sponsors Apple and Google!</i>
<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
1:30-2:45
</td>
<td></td>
<td>
Panel Discussion: practical concerns and open challenges in real-world deployments of differential privacy<br>
<i>Panelists: <a href="https://cs.colgate.edu/~mhay/">Michael Hay</a> (Tumult Labs), <a href="https://shlomi.hod.xyz/">Shlomi Hod</a> (Boston University), <a href="https://hona.kr/">James Honaker</a> (Mozilla Anonym), <a href="https://aterzis-personal.github.io/aterzis/">Andreas Terzis</a> (Google Research)</i>
<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
2:45-3:15
</td>
<td></td>
<td>
Break<br>
<i>Thanks to Silver level sponsors dpella and Tumult Labs!</i>
<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
3:15-4:45
</td>
<td></td>
<td>
<a href="#poster2">Poster Session #2</a>
<br>
</td>
</tr>
</table>

<br><br>
<table  style="padding:15px; column-gap:1000px">
<p><b>Wednesday, August 21</b></p>

<tr>
<td style="width: 100px;">
9:00-9:45
</td>
<td></td>
<td>

<button type="button" class="collapsible">Keynote: Data and privacy in data privacy<br>
<i>Matthew Jagielski (Invited Speaker)</i></button>
<div class="abstract">
  <p>This talk will cover three research directions pertinent to the DP community and relevant in modern machine learning. First, I will discuss training data attribution and high level connections to DP and membership inference. Next, I will cover data curation and potential intersections with differential privacy. Finally, I will discuss recent work on alternative privacy semantics tailored to modern use cases. In covering these areas, the primary focus will be on introducing the general directions to encourage interest and figure work. To this end, I will discuss my own work as well as others' when appropriate.</p>
<p><a href="https://jagielski.github.io/">Matthew Jagielski's website</a></p>
</div>

<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
9:45-10:30
</td>
<td></td>
<td>

<button type="button" class="collapsible">Differential privacy and Sublinear time are incompatible sometimes</a><br><i>Jeremiah Blocki, Hendrik Fichtenberger, Elena Grigorescu, <b>Tamalika Mukherjee</b></i></button>
<div class="abstract">
  <p>Differential privacy and sublinear algorithms are both rapidly emerging algorithmic themes in times of big data analysis. Although recent works have shown the existence of differentially private sublinear algorithms for many problems including graph parameter estimation and clustering, little is known regarding hardness results on these algorithms. In this paper, we initiate the study of lower bounds for problems that aim for both differentially-private and sublinear-time algorithms. Our main result is the incompatibility of both the desiderata in the general case. In particular, we prove that a simple problem based on one-way marginals yields both a differentially-private algorithm, as well as a sublinear-time algorithm, but does not admit a "strictly" sublinear-time algorithm that is also differentially private.</p>
</div>

<button type="button" class="collapsible">Instance-Optimal Private Density Estimation in the Wasserstein Distance</a><br><i>Vitaly Feldman, Audra McMillan, <b>Satchit Sivakumar</b>, Kunal Talwar</i></button>
<div class="abstract">
  <p>In this work, we study density estimation in the Wasserstein distance (an appropriate metric in many practical settings like estimating population density). We move beyond (pessimistic) worst-case bounds for this problem and instead approach it from an 'instance optimality' lens- asking that algorithms adapt to easy instances.  We define strong notions of instance optimality, characterize the corresponding instance optimal rates, and show that variants of practical algorithms achieve these rates (up to polylogarithmic factors).</p>
</div>

<button type="button" class="collapsible">Sample-Optimal Locally Private Hypothesis Selection and the Provable Benefits of Interactivity</a><br><i>Alireza F. Pour, <b>Hassan Ashtiani</b>, Shahab Asoodeh</i></button>
<div class="abstract">
  <p>We study the problem of hypothesis selection under the constraint of local differential privacy (ε-LDP). Our main contribution is the first sample-optimal algorithm for this problem in the high privacy regime. Namely, the dependence of the proposed algorithm on the number of hypotheses is linear. This algorithm uses loglog k rounds of (sequential) interaction for choosing from k hypotheses. Our result demonstrates the power of interaction in LDP hypothesis selection as any non-interactive algorithm requires at least Ω(klogk) samples. To prove our results, we define the notion of critical queries for a Statistical Query Algorithm (SQA) which may be of independent interest. Informally, an SQA is said to use a small number of critical queries if its success relies on the accuracy of only a small number of queries it asks. We then design an LDP algorithm that uses a smaller number of critical queries.</p>
</div>

</td>
</tr>

<tr>
<td style="width: 100px;">
10:30-11:00
</td>
<td></td>
<td>
Break<br>
<i>Thanks to Silver level sponsors dpella and Tumult Labs!</i>
<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
11:00-12:30
</td>
<td></td>
<td>
<a href="#poster3">Poster Session #3</a>
<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
12:30-1:30
</td>
<td></td>
<td>
Lunch (provided)<br>
<i>Thanks to Platinum level sponsors Apple and Google!</i>
<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
1:30-2:15
</td>
<td></td>
<td>

<button type="button" class="collapsible">Keynote: Bridging the Researcher/Non-Researcher Divide<br>
<i>Naomi Lefkovitz (Invited Speaker)</i></button>
<div class="abstract">
  <p>While the track to effective deployment of differential privacy (DP) may depend on quality research,
there are a number of non-research factors that can derail would-be implementers. This keynote will cover
current challenges organizations are facing in their efforts to deploy DP, ranging from knowledge gaps, people
problems, risk calculations, and more.</p>
<p><a href="https://www.nist.gov/people/naomi-lefkovitz">Naomi Lefkovitz's website</a></p>
</div>

<br>
</td>
</tr>

<tr>
<td style="width: 100px;">
2:15-3:00
</td>
<td></td>
<td>

<button type="button" class="collapsible">Joint Selection: Adaptively Incorporating Public Information for Private Synthetic Data<br><i><b>Miguel Fuentes</b>, Brett Mullins, Ryan McKenna, Gerome Miklau, Daniel Sheldon, Brett Mullins</i></button>
<div class="abstract">
  <p>Mechanisms for generating differentially private synthetic data based on marginals and graphical models have been successful in a wide range of settings. However, one limitation of these methods is their inability to incorporate public data. Initializing a data generating model by pre-training on public data has shown to improve the quality of synthetic data, but this technique is not applicable when model structure is not determined a priori. We develop the mechanism JAM-PGM, which expands the adaptive measurements framework to jointly select between measuring public data and private data. This technique allows for public data to be included in a graphical-model-based mechanism. We show that jam-pgm is able to outperform both publicly assisted and non publicly assisted synthetic data generation mechanisms even when the public data distribution is biased.</p>
</div>

<button type="button" class="collapsible">Private Fine-tuning of Large Language Models with Zeroth-order Optimization<br><i>Xinyu Tang, <b>Ashwinee Panda</b>, Milad Nasr, Saeed Mahloujifar, Prateek Mittal</i></button>
<div class="abstract">
  <p>DP-SGD is the workhorse algorithm for private deep learning, but has proven difficult to scale to the era of foundation models. We introduce DP-ZO, a framework for privatizing zeroth order optimization methods. Unlike DP-SGD methods, such as DP-LoRA, DP-ZO does not require implementing the cumbersome per-sample gradient clipping operation because the update information from each sample is a scalar. DP-ZO methods are competitive in utility with DP-SGD while using far less memory, and we contend that DP-ZO methods may be superior to DP-SGD for finetuning models at the foundation scale. We outline a number of future directions for improving the analysis and implementation of DP-ZO methods.</p>
</div>

<button type="button" class="collapsible">Provable Privacy with Non-Private Pre-Processing<br><i><b>Yaxi Hu</b>, Amartya Sanyal, Bernhard Schölkopf</i></button>
<div class="abstract">
  <p>When analysing Differentially Private (DP) machine learning pipelines, the potential privacy cost of data-dependent pre-processing is frequently overlooked in privacy accounting. In this work, we propose a general framework to evaluate the additional privacy cost incurred by non-private data-dependent pre-processing algorithms. Our framework establishes upper bounds on the overall privacy guarantees by utilising two new technical notions: a variant of DP termed Smooth DP and the bounded sensitivity of the pre-processing algorithms. In addition to the generic framework, we provide explicit overall privacy guarantees for multiple data-dependent pre-processing algorithms, such as scaling, data imputation, quantization, deduplication and PCA, when used in combination with several DP algorithms. Notably, this framework is also simple to implement, allowing direct integration into existing DP pipelines.</p>
</div>

</td>
</tr>

<tr>
<td style="width: 100px;">
3:00-6:00
</td>
<td></td>
<td>
TPDP/OpenDP Community Meeting Reception<br>
<i>Refreshments provided. Thanks to Diamond level sponsors Capital One, Microsoft, and Oblivious!</i>
</td>
</tr>

</table>
</div>

<div class="content box"> <h2>Accepted Papers</h2>

<a name="poster1"></a>
<p><b>Poster Session 1 </b></p>
<ul>
<li><a href="https://arxiv.org/pdf/2309.17330">Optimal Bounds on Private Graph Approximation</a><br><i>Jingcheng Liu, Jalaj Upadhyay, Zongrui Zou</i></li><br>
<li><a href="https://arxiv.org/abs/2312.07706">Near-Optimal Differentially Private k-Core Decomposition</a><br><i>Laxman Dhulipala, Monika Henzinger, George Li, Quanquan Liu, AR Sricharan, Leqi Zhu</i></li><br>
<li><a href="https://arxiv.org/abs/2403.05073">Private Count Release: A Simple and Scalable Approach for Private Data Analytics</a><br><i>Ryan Rogers</i></li><br>
<li>Bounding contribution optimally for Federated Frequency Estimation under User-level Distributed Differential Privacy<br><i>Seng Pei Liew, Tsubasa Takahashi</i></li><br>
<li><a href="https://arxiv.org/abs/2401.10371">Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning</a><br><i>Eli Chien, Haoyu Wang, Ziang Chen, Pan Li</i></li><br>
<li><a href="https://arxiv.org/abs/2308.14716">Local Lipschitz Filters for Bounded-Range Functions with Applications to Arbitrary Real-Valued Functions</a><br><i>Jane Lange, Ephraim Linder, Sofya Raskhodnikova, Arsen Vasilyan</i></li><br>
<li><a href="https://arxiv.org/abs/2402.06465">On Differentially Private Subspace Estimation Without Distributional Assumptions</a><br><i>Eliad Tsfadia</i></li><br>
<li>Differentially Private Parameter-Efficient Fine-tuning for Large ASR Models<br><i>Hongbin Liu, Lun Wang, Om Thakkar, Ahbradeep Thakurta, Arun Narayanan</i></li><br>
<li><a href="https://arxiv.org/abs/2403.17673">How Private are DP-SGD Implementations?</a><br><i>Lynn Chua, Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Amer Sinha, Chiyuan Zhang</i></li><br>
<li>Profile Reconstruction from Private Sketches<br><i>Hao Wu, Rasmus Pagh</i></li><br>
<li><a href="https://arxiv.org/abs/2403.01749">Differentially Private Synthetic Data via Foundation Model APIs 2: Text</a><br><i>Chulin Xie, Zinan Lin, Arturs Backurs, Sivakanth Gopi, Da Yu, Huseyin A Inan, Harsha Nori, Haotian Jiang, Huishuai Zhang, Yin Tat Lee, Bo Li, Sergey Yekhanin</i></li><br>
<li><a href="https://arxiv.org/abs/2402.10065">Quantifying the Per-datum Membership Leakage</a><br><i>Achraf AZIZE, Debabrota BASU</i></li><br>
<li><a href="https://arxiv.org/abs/2309.02202">On the Complexity of Differentially Private Best-Arm Identification with Fixed Confidence</a><br><i>Achraf AZIZE, Marc JOURDAN, Aymen Al Marjani, Debabrota BASU</i></li><br>
<li><a href="https://arxiv.org/abs/2310.09639">DPZero: Private Fine-Tuning of Language Models without Backpropagation</a><br><i>Liang Zhang, Bingcong Li, Kiran Koshy Thekumparampil, Sewoong Oh, Niao He</i></li><br>
<li><a href="https://arxiv.org/abs/2405.01031">The Privacy Power of Correlated Noise in Decentralized Learning</a><br><i>Youssef Allouah, Anastasia Koloskova, Aymane El Firdoussi, Martin Jaggi, Rachid Guerraoui</i></li><br>
<li><a href="https://arxiv.org/abs/2404.16706">Efficient and Near-Optimal Noise Generation for Streaming Differential Privacy</a><br><i>Krishnamurthy (Dj) Dvijootham, H. Brendan McMahan, Krishna Pillutla, Thomas Steinke, Abhradeep Thakkurta, Krishna Pillutla</i></li><br>
<li><a href="https://arxiv.org/abs/2407.04776">Quantifying Privacy Risks of Public Statistics to Residents of Subsidized Housing</a><br><i>Ryan Steed, Diana Qing, Zhiwei Steven Wu</i></li><br>
<li>Better Gaussian Mechanism using Correlated Noise<br><i>Christian Janos Lebeda</i></li><br>
<li><a href="https://arxiv.org/abs/2310.13137">Mean Estimation Under Heterogeneous Privacy Demands</a><br><i>Syomantak Chaudhuri, Konstantin Miagkov, Thomas A. Courtade</i></li><br>
<li><a href="https://arxiv.org/pdf/2407.09690">Private Heterogeneous Federated Learning Without a Trusted Server Revisited: Error-Optimal and Communication-Efficient Algorithms for Convex Losses</a><br><i>Changyu Gao, Andrew Lowy, Stephen J. Wright, Xingyu Zhou</i></li><br>
<li>The Pervasiveness of Timing Side Channels in Differential Privacy<br><i>Zachary Ratliff, Nicolas Berrios, James Mickens, Nicolas Berrios</i></li><br>
<li><a href="https://arxiv.org/abs/2402.09477">PANORAMIA: Privacy Auditing of Machine Learning Models without Retraining</a><br><i>Mishaal Kazmi, Hadrien Lautraite, Alireza Akbari, Mauricio Soroco, Qiaoyue Tang, Tao Wang, Sébastien Gambs, Mathias Lécuyer</i></li><br>
<li><a href="https://arxiv.org/abs/2404.17714">Lower Bounds for Private Estimation of Gaussian Covariance Matrices under All Reasonable Parameter Regimes</a><br><i>Victor Sanches Portella, Nick Harvey</i></li><br>
<li><a href="https://xingyuzhou.org/publications/LDPR-MAB.pdf">Locally Private and Robust Multi-Armed Bandits</a><br><i>Wei Zhang, Xingyu Zhou</i></li><br>
<li><a href="https://arxiv.org/pdf/2406.04610">Constrastive explainable clustering with differential privacy</a><br><i>Dung Nguyen, Ariel Vetzler, Sarit Kraus, Anil Vullikanti</i></li><br>
<li><a href="https://cs-people.bu.edu/grbrown/BrownZakynthinou_TPDP_Abstract.pdf">Tukey Depth Mechanisms for Practical Private Mean Estimation</a><br><i>Gavin Brown, Lydia Zakynthinou, Gavin Brown</i></li><br>
<li>Differential-Privacy Capacity<br><i>Wael Alghamdi, Shahab Asoodeh, Flavio P. Calmon, Oliver Kosut, Lalitha Sankar</i></li><br>
<li><a href="https://arxiv.org/pdf/2405.02341">Improved Communication-Privacy Trade-offs in L2 Mean Estimation under Streaming Differential Privacy</a><br><i>Wei-Ning Chen, Berivan Isik, Peter Kairouz, Albert No, Sewoong Oh, Zheng Xu</i></li><br>
<li>User-level Differentially Private Stochastic Convex Optimization: Efficient Algorithms with Optimal Rates<br><i>Hilal Asi, Daogao Liu</i></li><br>
<li><a href="https://arxiv.org/pdf/2310.09266">User Inference for Large Language Models</a><br><i>Nikhil Kandpal, Krishna Pillutla, Alina Oprea, Peter Kairouz, Christopher A. Choquette-Choo, Zheng Xu</i></li><br>
<li><a href="https://arxiv.org/abs/2301.08517">Cohere: Managing Differential Privacy in Large Scale Systems</a><br><i>Nicolas Küchler, Emanuel Opel, Hidde Lycklama, Alexander Viand, Anwar Hithnawi</i></li><br>
<li><a href="https://arxiv.org/abs/2309.03847">Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples</a><br><i>Mohammad Afzali, Hassan Ashtiani, Christopher Liaw</i></li><br>
<li><a href="https://arxiv.org/abs/2408.07021">Improved Counting under Continual Observation with Pure Differential Privacy</a><br><i>Joel Daniel Andersson, Rasmus Pagh, Sahel Torkamani</i></li><br>
<li><a href="https://arxiv.org/abs/2406.02797">Auditing Privacy Mechanisms via Label Inference Attacks</a><br><i>Robert Istvan Busa-Fekete, Travis Dick, Claudio Gentile, Andrés Muñoz Medina, Adam Smith, Marika Swanberg</i></li><br>
<li>Slowly Scaling Per-Record Differential Privacy<br><i>Brian Finley, Anthony M Caruso, Justin C Doty, Ashwin Machanavajjhala, Mikaela R Meyer, David Pujol, William Sexton, Zachary Terner</i></li><br>
<li>Private and Personalized Frequency Estimation in a Federated Setting<br><i>Amrith Setlur, Vitaly Feldman, Kunal Talwar</i></li><br>
</ul>

<a name="poster2"></a>
<p><b>Poster Session 2 </b></p>
<ul>
<li><a href="https://arxiv.org/abs/2406.03802">Continual Counting with Gradual Privacy Expiration</a><br><i>Joel Daniel Andersson, Monika Henzinger, Rasmus Pagh, Teresa Anna Steiner, Jalaj Upadhyay</i></li><br>
<li><a href="https://arxiv.org/abs/2309.15790">Some Constructions of Private, Efficient, and Optimal K-Norm and Elliptic Gaussian Noise</a><br><i>Matthew Joseph, Alexander Yu</i></li><br>
<li>Navigating Privacy: Exploring Perceptions, Practices, and Challenges Among Data Privacy Experts<br><i>Isabela Bertolini Coelho, Frauke Kreuter</i></li><br>
<li>Hash-Prune-Invert: Differentially PrivateHeavy-Hitters in the Two-Server Model<br><i>Borja Balle, James Bell, Albert Cheu, Adria Gascon, Jonathan Katz, Mariana Raykova, Phillipp Schoppmann, Thomas Steinke, Albert Cheu</i></li><br>
<li>Differentially Private Sequential Learning<br><i>Yuxin Liu, Amin Rahimian</i></li><br>
<li>Metric Differential Privacy at the User-level<br><i>Jacob Imola, Amrita Roy Chowdhury, Kamalika Chaudhuri</i></li><br>
<li><a href="https://arxiv.org/abs/2307.02969">DPM: Clustering Sensitive Data through Separation</a><br><i>Johannes Liebenow, Yara Schütt, Tanya Braun, Marcel Gehrke, Florian Thaeter, Esfandiar Mohammadi</i></li><br>
<li><a href="https://www.nature.com/articles/s43856-024-00462-6">Differential Privacy in Large-Scale AI Models: Ensuring Fairness and Diagnostic Accuracy in Medical Imaging</a><br><i>Soroosh Tayebi Arasteh, Alexander Ziller, Daniel Truhn, Georgios Kaissis</i></li><br>
<li><a href="https://arxiv.org/abs/2405.15002">Private Regression via Data-Dependent Sufficient Statistic Perturbation</a><br><i>Cecilia Ferrando, Daniel Sheldon</i></li><br>
<li>Revealing the Underestimated Privacy of the 2020 United States Census<br><i>Buxin Su, Weijie Su, Chendi Wang</i></li><br>
<li><a href="https://eprint.iacr.org/2023/1523">On the Privacy of Sublinear-Communication Jaccard Index Estimation via Min-hash Sketching</a><br><i>Seung Geol Choi, Dana Dachman-Soled, Mingyu Liang, Linsheng Liu, Arkady Yerukhimovich</i></li><br>
<li><a href="https://arxiv.org/abs/2405.01716">ATTAXONOMY: Unpacking Differential Privacy Guarantees Against Practical Adversaries</a><br><i>Rachel Cummings, Shlomi Hod, Jayshree Sarathy, Marika Swanberg</i></li><br>
<li><a href="https://arxiv.org/abs/2402.11119">Private PAC Learning May be Harder than Online Learning</a><br><i>Mark Bun, Aloni Cohen, Rathin Desai</i></li><br>
<li><a href="https://tpdp.journalprivacyconfidentiality.org/2024/pdfs/A%20Visualization%20Tool%20to%20Help%20Technical%20Practitioners%20of%20Differential%20Privacy.pdf">A Visualization Tool to Help Technical Practitioners of Differential Privacy</a><br><i>Liudas Panavas, Saeyoung Rho, Hari Bhimaraju, Wynee Pintado, Rebecca Wright, Rachel Cummings</i></li><br>
<li>Differential privacy and Sublinear time are incompatible sometimes<br><i>Jeremiah Blocki, Hendrik Fichtenberger, Elena Grigorescu, Tamalika Mukherjee</i></li><br>
<li><a href="https://arxiv.org/abs/2403.03856">Public-data Assisted Private Stochastic Optimization: Power and Limitations</a><br><i>Enayat Ullah, Michael Menart, Raef Bassily, Cristobal Guzman, Raman Arora, Enayat Ullah</i></li><br>
<li><a href="https://tpdp.journalprivacyconfidentiality.org/2024/pdfs/Scalable%20Private%20Set%20Union%20Beyond%20Uniform%20Weighting.pdf">Scalable Private Set Union Beyond Uniform Weighting</a><br><i>Justin Chen, Vincent Cohen-Addad, Alessandro Epasto, Morteza Zadimoghaddan</i></li><br>
<li><a href="https://arxiv.org/abs/2406.19566">Instance-Optimal Private Density Estimation in the Wasserstein Distance</a><br><i>Vitaly Feldman, Audra McMillan, Satchit Sivakumar, Kunal Talwar</i></li><br>
<li><a href="https://tpdp.journalprivacyconfidentiality.org/2024/pdfs/Reconstruction%20Attacks%20on%20Machine%20Unlearning.pdf">Reconstruction Attacks on Machine Unlearning: Simple Models are Vulnerable</a><br><i>Martin Bertran, Shuai Tang, Michael Kearns, Jamie Heather Morgenstern, Aaron Roth, Zhiwei Steven Wu</i></li><br>
<li><a href="https://tpdp.journalprivacyconfidentiality.org/2024/pdfs/Enhanced%20Privacy-Preserving%20Decision%20Trees%20using%20Secure%20Multiparty%20Computation%20and%20Differential%20Privacy.pdf">Enhanced Privacy-Preserving Decision Trees using Secure Multiparty Computation and Differential Privacy</a><br><i>Arisa Tajima, Wei Jiang, Virendra Marathe, Hamid Mozaffari</i></li><br>
<li><a href="https://openreview.net/pdf?id=xqqccG7gf1">Membership Inference Attacks on Diffusion Models via Quantile Regression</a><br><i>Shuai Tang, Zhiwei Steven Wu, Sergul Aydore, Michael Kearns, Aaron Roth</i></li><br>
<li>Sample-Optimal Locally Private Hypothesis Selection and the Provable Benefits of Interactivity<br><i>Alireza F. Pour, Hassan Ashtiani, Shahab Asoodeh</i></li><br>
<li><a href="https://proceedings.mlr.press/v238/fuentes24a/fuentes24a.pdf ">Joint Selection: Adaptively Incorporating Public Information for Private Synthetic Data</a><br><i>Miguel Fuentes, Brett Mullins, Ryan McKenna, Gerome Miklau, Daniel Sheldon, Brett Mullins</i></li><br>
<li><a href="https://arxiv.org/abs/2402.16778">On the Growth of Mistakes in Differentially Private Online Learning: A Lower Bound Perspective</a><br><i>Daniil Dmitriev, Kristóf Szabó, Amartya Sanyal, Amartya Sanyal</i></li><br>
<li><a href="https://tpdp.journalprivacyconfidentiality.org/2024/pdfs/Privately%20Evaluating%20Untrusted%20Black-Box%20Functions.pdf">Privately Evaluating Untrusted Black-Box Functions</a><br><i>Ephraim Linder, Sofya Raskhodnikova, Adam Smith, Thomas Steinke</i></li><br>
<li><a href="https://tpdp.journalprivacyconfidentiality.org/2024/pdfs/Efficient%20Decision%20Procedures%20for%20Differential%20Privacy%20via%20Probabilistic%20Couplings.pdf">Efficient Decision Procedures for Differential Privacy via Probabilistic Couplings</a><br><i>Azadeh Farzan, Sky Li, Aleksandar Nikolov, Vishnu Nittoor</i></li><br>
<li><a href="https://arxiv.org/pdf/2407.17619">Sublinear Space Graph Algorithms in the Continual Release Model via Sparsification</a><br><i>Alessandro Epasto, Quanquan C. Liu, Tamalika Mukherjee, Felix Zhou</i></li><br>
<li>Inconsistency measures for Differentially Private databases<br><i>Shubhankar Mohapatra, Amir Gilad, Xi He, Benny Kimelfeld</i></li><br>
<li>Equitable Differential Privacy<br><i>Vasundhara Kaul, Tamalika Mukherjee</i></li><br>
<li><a href="https://arxiv.org/abs/2407.02191">Attack-Aware Noise Calibration for Differential Privacy</a><br><i>Bogdan Kulynych, Juan Felipe Gomez, Georgios Kaissis, Flavio du Pin Calmon, Carmela Troncoso</i></li><br>
<li>Formal Privacy Guarantees with Invariant Statistics<br><i>Young Hyun Cho, Jordan Awan</i></li><br>
<li><a href="https://abiswas3.github.io/papers/DPHHH.pdf">Differentially Private Hierarchical Heavy Hitters</a><br><i>Ari Biswas, Graham Cormode, Yaron Kanza, Divesh Srivastava, Zhengyi Zhou</i></li><br>
<li><a href="https://tpdp.journalprivacyconfidentiality.org/2024//pdfs/Private_Selection_with_Heterogeneous_Sensitivities-2.pdf">Private Selection with Heterogeneous Sensitivities</a><br><i>Daniela Antonova, Allegra Latimer Laro, Audra McMillan, Lorenz Wolf</i></li><br>
<li>Private Vector Mean Estimation in the Shuffle Model: Optimal Rates Require Many Messages<br><i>Hilal Asi, Vitaly Feldman, Jelani Nelson, Huy L. Nguyen, Kunal Talwar, Samson Zhou</i></li><br>
<li><a href="https://arxiv.org/pdf/2405.15913v1">Scaling up the Amplified Banded Matrix Factorization Mechanism for Differentially Private ML</a><br><i>Ryan McKenna</i></li><br>
<li><a href="https://github.com/SankarLab/Renyi-DP-Mechanism-Design/blob/5c9f1efb8ea4d4b9321d06117bb6c024989f323f/Optimizing%20Discrete%20Noise%20Distributions%20for%20Renyi%20Differential%20Privacy.pdf">Optimizing Discrete Noise Distributions for Renyi Differential Privacy</a><br><i>Atefeh Gilani, Juan Felipe Gomez, Shahab Asoodeh, Flavio P. Calmon, Oliver Kosut, Lalitha Sankar</i></li><br>
<li><a href="https://arxiv.org/abs/2408.07614">Practical Considerations for Differential Privacy</a><br><i>Kareem Amin, Alex Kulesza, Sergei Vassilvitskii</i></li><br>
<li><a href="https://arxiv.org/abs/2310.14661">Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy</a><br><i>Yingyu Lin, Yi-An Ma, Yu-Xiang Wang, Rachel Redberg, Zhiqi Bu</i></li><br>
<li>Adapting Differentially Private Synthetic Data to Relational Databases<br><i>Kaveh Alimohammadi, Hao Wang, Ojas Gulati, Akash Srivastava, Navid Azizan</i></li><br>
</ul>

<a name="poster3"></a>
<p><b>Poster Session 3 </b></p>
<ul>
<li><a href="https://openreview.net/pdf?id=5kXNMDpUVF">New Linear Scaling Rule for Private Adaptive Hyperparameter Optimization</a><br><i>Ashwinee Panda, Xinyu Tang, Saeed Mahloujifar, Vikash Sehwag, Prateek Mittal</i></li><br>
<li><a href="https://arxiv.org/pdf/2401.04343">Private Fine-tuning of Large Language Models with Zeroth-order Optimization</a><br><i>Xinyu Tang, Ashwinee Panda, Milad Nasr, Saeed Mahloujifar, Prateek Mittal</i></li><br>
<li><a href="https://arxiv.org/pdf/2402.11173">How to Make the Gradients Small Privately: Improved Rates for Differentially Private Non-Convex Optimization</a><br><i>Andrew Lowy, Jonathan Ullman, Stephen J. Wright</i></li><br>
<li>Private Means and the Curious Incident of the Free Lunch<br><i>Jack Fitzsimons, James Honaker, Michael Shoemate, Vikrant Singhal</i></li><br>
<li><a href="https://arxiv.org/abs/2406.01457">Differentially Private Tabular Data Synthesis using Large Language Models</a><br><i>Toan Tran, Li Xiong</i></li><br>
<li>Synthesizing Tight Privacy and Accuracy Bounds via Weighted Model Counting<br><i>Lisa Oakley, Steven Holtzen, Alina Oprea</i></li><br>
<li><a href="https://tpdp.journalprivacyconfidentiality.org/2024/pdfs/Mean%20Estimation%20Strikes%20Back!%20An%20Efficient%20Solution%20to%20Private%20Classification.pdf">Mean Estimation Strikes Back! An Efficient Solution to Private Classification</a><br><i>Yuqing Zhu, Huanyu Zhang</i></li><br>
<li>Differentially Private Maximum Matching in General Graphs<br><i>Michael Dinitz, George Li, Quanquan Liu</i></li><br>
<li><a href="https://arxiv.org/abs/2402.07066">Differentially Private Range Queries with Correlated Input Perturbation</a><br><i>Prathamesh Dharangutte, Jie Gao, Ruobin Gong, Guanyang Wang</i></li><br>
<li><a href="https://tpdp.journalprivacyconfidentiality.org/2024/pdfs/Federated%20Online%20Prediction%20from%20Experts%20with%20Differential%20Privacy-%20Separations%20and%20Regret%20Speed-ups.pdf">Federated Online Prediction from Experts with Differential Privacy: Separations and Regret Speed-ups</a><br><i>Fengyu Gao, Ruiquan Huang, Jing Yang</i></li><br>
<li><a href="https://arxiv.org/abs/2404.15409">Insufficient Statistics Perturbation: Stable Estimators for Private Least Squares</a><br><i>Gavin Brown, Jonathan Hayase, Samuel Hopkins, Weihao Kong, Xiyang Liu, Sewoong Oh, Juan C. Perdomo, Adam Smith</i></li><br>
<li><a href="https://arxiv.org/abs/2408.04888">Locally Private Histograms in All Privacy Regimes</a><br><i>Clément Canonne, Abigail Gentle</i></li><br>
<li><a href="https://arxiv.org/abs/2406.07407">Private Geometric Median</a><br><i>Mahdi Haghifam, Jonathan Ullman</i></li><br>
<li><a href="https://arxiv.org/abs/2312.03724">DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer</a><br><i>Junyuan Hong, Jiachen T. Wang, Chenhui Zhang, Zhangheng Li, Bo Li, Zhangyang Wang</i></li><br>
<li><a href="http://savs95.github.io/tpdp">Sharper Bounds for Chebyshev Moment Matching with Applications to Differential Privacy and Beyond</a><br><i>Cameron Musco, Christopher Musco, Lucas Rosenblatt, Apoorv Vikram Singh</i></li><br>
<li>Locally Differentially Private Histogram Estimation in the Federated Setting<br><i>Ziyu Huang, Tingting Ou, Rachel Cummings</i></li><br>
<li>FedPrivSyn: Federated Differentially Private Data Synthesis<br><i>XIZIXIANG WEI, Tianhao Wang, JING YANG, Cong Shen</i></li><br>
<li>Dimension-free Private Mean Estimation for Anisotropic Gaussians<br><i>Yuval Dagan, Michael I. Jordan, Xuelin Yang, Lydia Zakynthinou, Nikita Zhivotovskiy</i></li><br>
<li>S-BDT: Distributed Differentially Private Boosted Decision Trees<br><i>Thorsten Peinemann, Moritz Kirschte, Joshua Stock, Carlos Cotrini, Esfandiar Mohammadi</i></li><br>
<li>Privacy Pitfalls and Opportunities in Imbalanced Learning<br><i>Lucas Rosenblatt, Yuliia Lut, Eitan Turok, Marco Avella-Medina, Rachel Cummings</i></li><br>
<li>On the Formal Privacy Guarantees of Synthetic Data<br><i>Marcel Neunhoeffer, Jonathan Latner, Joerg Drechsler</i></li><br>
<li>Lower Bounds for Differential Privacy Under Continual Observation and its Implications<br><i>Edith Cohen, Xin Lyu, Jelani Nelson, Tamás Sarlós, Uri Stemmer</i></li><br>
<li><a href="https://arxiv.org/abs/2405.13677">Naturally Private Recommendations with Determinantal Point Processes</a><br><i>Robert Pisarczyk, Jack Fitzsimons, Agustín Freitas Pasqualini, Dmitrii Usynin</i></li><br>
<li>An Attack Agnostic Approach to Empirical Privacy<br><i>Kevin Liou, Tamara Greasby, James Honaker</i></li><br>
<li><a href="https://arxiv.org/pdf/2406.02140">Optimality of Matrix Mechanism on $\ell_p^p$-metric</a><br><i>Jingcheng Liu, Jalaj Upadhyay, Zongrui Zou</i></li><br>
<li><a href="https://arxiv.org/abs/2402.06701">Privacy Profiles for Private Selection</a><br><i>Antti Koskela, Rachel Redberg, Yu-Xiang Wang</i></li><br>
<li>Efficient and Private Marginal Reconstruction with Local Non-negativity<br><i>Brett Mullins, Miguel Fuentes, Yingtai Xiao, Daniel Kifer, Cameron Musco, Daniel Sheldon</i></li><br>
<li><a href="https://arxiv.org/abs/2306.04564">Differentially Private Selection from Secure Distributed Computing</a><br><i>Ivan Damgård, Hannah Keller, Boel Nelson, Claudio Orlandi, Rasmus Pagh</i></li><br>
<li><a href="https://arxiv.org/abs/2405.20782">Universal Exact Compression of Differentially Private Mechanisms</a><br><i>Yanxiao Liu, Wei-Ning Chen, Ayfer Özgür, Cheuk Ting Li</i></li><br>
<li>Correlated Mechanisms for Differentially Private Distributed Mean Estimation<br><i>Sajani Vithana, Viveck R. Cadambe, Flavio P. Calmon, Haewon Jeong</i></li><br>
<li><a href="https://arxiv.org/abs/2408.06997">Faster Private Minimum Spanning Trees</a><br><i>Rasmus Pagh, Lukas Retschmeier</i></li><br>
<li>Perturb-and-Project: Differentially Private Similarities and Marginals<br><i>Vincent Cohen-Addad, Tommaso D'Orsi, Alessandro Epasto, Vahab Mirrokni, Peilin Zhong</i></li><br>
<li><a href="https://arxiv.org/pdf/2403.13041">Provable Privacy with Non-Private Pre-Processing</a><br><i>Yaxi Hu, Amartya Sanyal, Bernhard Schölkopf</i></li><br>
<li><a href="https://arxiv.org/abs/2402.08156">Group Decision-Making among Privacy-Aware Agents</a><br><i>Marios Papachristou, Amin Rahimian</i></li><br>
</ul>


<a name="videos"></a>
<p><b>Virtual presentations</b></p>
<ul>
<li>M-Estimation Under User-Level Local Privacy Constraints<br><i>Lekshmi Ramesh, Elise Han, Marco Avella-Medina, Cynthia Rush</i></li><br>
<li><a href="https://arxiv.org/pdf/2401.17628">Elephants Do Not Forget: Differential Privacy with State Continuity for Privacy Budget</a><br><i>Jiankai Jin, Chitchanok Chuengsatiansup, Toby Murray, Benjamin I. P. Rubinstein, Yuval Yarom, Olga Ohrimenko</i></li><br>
<li>Querycheetah: Fast Automated Discovery of Attribute Inference Attacks Against Query-Based Systems<br><i>Bozhidar Stevanoski, Ana-Maria Cretu, Yves-Alexandre de Montjoye</i></li><br>
<li><a href="https://arxiv.org/abs/2406.12103v1">Centering Policy and Practice: Research Gaps around Usable Differential Privacy</a><br><i>Rachel Cummings, Jayshree Sarathy</i></li><br>
</ul>

</div>

<div class="content box">

<h2>Call for Papers</h2>

<p>
Differential privacy (DP) is the leading framework for data analysis with rigorous privacy guarantees. In the last 18 years, it has transitioned from the realm of pure theory to large scale, real world deployments.
</p>
<p>
Differential privacy is an inherently interdisciplinary field, drawing researchers from a variety of academic communities including machine learning, statistics, security, theoretical computer science, databases, and law. The combined effort across a broad spectrum of computer science is essential for differential privacy to realize its full potential.  To this end, this workshop aims to stimulate discussion among participants about both the state-of-the-art in differential privacy and the future challenges that must be addressed to make differential privacy more practical.
</p>

<p>
Specific topics of interest for the workshop include (but are not limited to):
</p>
<ul>
<li>Theory of DP</li>
<li>DP and security</li>
<li>Privacy preserving machine learning</li>
<li>DP and statistics</li>
<li>DP and data analysis</li>
<li>Trade-offs between privacy protection and analytic utility</li>
<li>DP and surveys</li>
<li>Programming languages for DP</li>
<li>Relaxations of DP</li>
<li>Relation to other privacy notions and methods</li>
<li>Experimental studies using DP</li>
<li>DP implementations</li>
<li>DP and policy making</li>
<li>Applications of DP</li>
<li>Reconstruction attacks and memorization</li>
</ul>


<p>
<b>Submissions:</b> Authors are invited to submit a short abstract of new work or work published since July 2023 (the most recent TPDP submission deadline). Submissions must be 4 pages maximum, not including references. Submissions may also include appendices, but these are only read at reviewer's discretion. There is no prescribed style file, but authors should ensure a minimum of 1-inch margins and 10pt font. Submissions are not anonymized, and should include author names and affiliations.
</p>

<p>
Submissions will undergo a lightweight review process and will be judged on originality, relevance, interest, and clarity. Based on the volume of submissions to TPDP 2023 and the workshop's capacity constraints, we expect that the review process will be somewhat more competitive than in years past. Accepted abstracts will be presented at the workshop either as a talk or a poster.
</p>

<p>
The workshop will not have formal proceedings and is not intended to preclude later publication at another venue. In-person attendance is encouraged, though authors of accepted abstracts who cannot attend in person will be invited to submit a short video to be linked on the TPDP website.
</p>

<p>
Selected papers from the workshop will be invited to submit a full version of their work for publication in a <a href="https://journalprivacyconfidentiality.org/index.php/jpc/tpdp">special issue</a> of the <a href="https://journalprivacyconfidentiality.org/index.php/jpc">Journal of Privacy and Confidentiality</a>.
</p>

</div>

<div class="side box">
  <h2>Registration</h2>
<dl>
Register for TPDP 2024
<a href="https://forms.gle/Q9S2sk1H6mMqCdmq5">here</a>!
  </dl>
<p>
</p>
</div>

<div class="side box">
  <h2>Important Dates</h2>
  <dl>
    <dt>Abstract Submission</dt>
    <dd>May 7, 2024 (AoE)</dd>
    <dt>Notification</dt>
    <dd>July 9, 2024</dd>
    <dt>Workshop</dt>
    <dd>August 20-21, 2024</dd>
  </dl>
</div>

<div class="side box">
<h2 id="corpsponsor">Corporate Sponsors</h2>

<p>
We are very grateful to our sponsors whose generosity has been critical to the continued success of the workshop. For information about sponsorship opportunities, please contact us at <a href="mailto:tpdp.chairs@gmail.com">tpdp.chairs@gmail.com</a>.
</p>

<h2 class="small-heading">Diamond Tier Sponsors</h2>
<p align="center"><img src="oblivious_logo.svg" alt="Oblivious logo" width="200"></p>
<p align="center"><img src="microsoft_logo.png" alt="Microsoft logo" width="200"></p>
<p align="center"><img src="capital_one_logo.svg" alt="Capital One logo" width="200"></p>

<h2 class="small-heading">Platinum Tier Sponsors</h2>

<p align="center"><img src="apple_logo.png" alt="Apple logo" width="80"></p>
<p align="center"><img src="google_logo.png" alt="Google logo" width="180"></p>

<h2 class="small-heading">Gold Tier Sponsors</h2>

<p align="center"><img src="meta_logo.jpg" alt="Meta logo" width="180"></p>
<p align="center"><img src="tiktok_logo.png" alt="Tiktok logo" width="180"></p>


<h2 class="small-heading">Silver Tier Sponsors</h2>

<p align="center"> <img src="tumult_logo.jpg" alt="Tumult logo" width="150"></p>
<p align="center">  <img src="dpella_logo.jpg" alt="DPella logo" width="150"></p>

<!-- <h3 class="small-heading">Bronze Tier Sponsors</h3> -->


</div>

<div class="side box">
  <h2>Submission website</h2>
<dl>
<a href="https://tpdp24.cs.uchicago.edu/">https://tpdp24.cs.uchicago.edu</a>
  </dl>
<p>
For concerns regarding submissions, please contact <a href="mailto:tpdp.chairs@gmail.com">tpdp.chairs@gmail.com</a>
</p>
</div>


<div class="side box">
  <h2>Organizing and Program Committee</h2>
  <ul>
    <li class="pc">
      <a href="https://aloni.net">Aloni Cohen</a> (co-chair)<br>
      University of Chicago
    </li>
    <li class="pc">
      <a href="https://www.uvm.edu/~jnear/">Joe Near</a> (co-chair)<br>
      University of Vermont
    </li>
<br>
<li class="pc">Adam Sealfon </li>
<li class="pc">Alejandro Russo </li>
<li class="pc">Aleksandar Nikolov </li>
<li class="pc">Alexandra Wood </li>
<li class="pc">Amartya Sanyal </li>
<li class="pc">Amin Rahimian </li>
<li class="pc">Amrita Roy Chowdhury </li>
<li class="pc">Anand Sarwate </li>
<li class="pc">Andrew Lowy </li>
<li class="pc">Annabelle McIver </li>
<li class="pc">Anne-Sophie Charest </li>
<li class="pc">Arkady Yerukhimovich </li>
<li class="pc">Ayelet Gordon-Tapiero </li>
<li class="pc">Borja Balle </li>
<li class="pc">Chiké Abuah </li>
<li class="pc">Christian Janos Lebeda </li>
<li class="pc">Christine Task </li>
<li class="pc">Clément Canonne </li>
<li class="pc">Cong Shen </li>
<li class="pc">Daniel Kifer </li>
<li class="pc">Daogao Liu </li>
<li class="pc">David Pujol </li>
<li class="pc">Eliad Tsfadia </li>
<li class="pc">Enayat Ullah </li>
<li class="pc">Gabriel Kaptchuk </li>
<li class="pc">Gary Howarth </li>
<li class="pc">Gautam Kamath </li>
<li class="pc">Gavin Brown </li>
<li class="pc">Giuseppe Vietri </li>
<li class="pc">Hilal Asi </li>
<li class="pc">Ivoline Ngong </li>
<li class="pc">Jalaj Upadhyay </li>
<li class="pc">James Honaker </li>
<li class="pc">Jayshree Sarathy </li>
<li class="pc">Jeremy Seeman </li>
<li class="pc">Joann Qiongna Chen </li>
<li class="pc">Joerg Drechsler </li>
<li class="pc">Johes Bater </li>
<li class="pc">Jonathan Ullman </li>
<li class="pc">Jordan Awan </li>
<li class="pc">Juba Ziani </li>
<li class="pc">Kobbi Nissim </li>
<li class="pc">Kunal Talwar </li>
<li class="pc">Ludmila Glinskih </li>
<li class="pc">Lun Wang </li>
<li class="pc">Lydia Zakynthinou </li>
<li class="pc">Mahdi Haghifam </li>
<li class="pc">Marika Swanberg </li>
<li class="pc">Matthew Jagielski </li>
<li class="pc">Matthew Joseph </li>
<li class="pc">Olya Ohrimenko </li>
<li class="pc">Om Thakkar </li>
<li class="pc">Or Sheffet </li>
<li class="pc">Palak Jain </li>
<li class="pc">Peter Kairouz </li>
<li class="pc">Samuel Haney </li>
<li class="pc">Satchit Sivakumar </li>
<li class="pc">Seng Pei Liew </li>
<li class="pc">Shlomi Hod </li>
<li class="pc">Shubhankar Mohapatra </li>
<li class="pc">Sofya Raskhodnikova </li>
<li class="pc">Stacey Truex </li>
<li class="pc">Terrance Liu </li>
<li class="pc">Tianhao Wang </li>
<li class="pc">Uri Stemmer </li>
<li class="pc">Vitaly Feldman </li>
<li class="pc">Viveck Cadambe </li>
<li class="pc">Wei-Ning Chen </li>
<li class="pc">Xi He </li>
<li class="pc">Xingyu Zhou </li>
<li class="pc">Xinyu Tang </li>
<li class="pc">Xuechen Li </li>
<li class="pc">Yaodong Yu </li>
<li class="pc">Yves-Alexandre de Montjoye </li>
<li class="pc">Zeyu Ding </li>

  </ul>
</div>


<div id="bg_descr">
</div>

<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}
</script>

</body></html>
